{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "import graph_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_frame = pd.read_csv(\"../processed_data/cc_mistral_ratings.csv\")\n",
    "chatgpt_frame = pd.read_csv(\"../processed_data/gptrated_frame.csv\")\n",
    "llama31_frame = pd.read_csv(\"../processed_data/cc_llama31_ratings.csv\")\n",
    "\n",
    "edstays = pd.read_csv(\"../raw_data/edstay_encounters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unrated from mistral -1\n",
    "mistral_frame = mistral_frame[mistral_frame[\"rating\"] != -1]\n",
    "\n",
    "# remove unrated from llama31 -1\n",
    "llama31_frame = llama31_frame[llama31_frame[\"rating\"] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_ed = edstays.copy()\n",
    "chatgpt_ed = edstays.copy()\n",
    "llama31_ed = edstays.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590923/969570883.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  mistral_ed['rating'].fillna(-9999, inplace=True)\n",
      "/tmp/ipykernel_590923/969570883.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  chatgpt_ed['rating'].fillna(-9999, inplace=True)\n",
      "/tmp/ipykernel_590923/969570883.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  llama31_ed['rating'].fillna(-9999, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from mistral_frame\n",
    "rating_dict = mistral_frame.set_index(\"chiefcomplaint\")[\"rating\"].to_dict()\n",
    "\n",
    "# Map the dictionary to the 'chiefcomplaint' column in mistral_ed\n",
    "mistral_ed[\"rating\"] = mistral_ed[\"chiefcomplaint\"].map(rating_dict)\n",
    "\n",
    "# Replace NaN values with -9999\n",
    "mistral_ed[\"rating\"].fillna(-9999, inplace=True)\n",
    "\n",
    "# Repeat the process for chatgpt_ed and chatgpt_frame\n",
    "rating_dict = chatgpt_frame.set_index(\"chiefcomplaint\")[\"rating\"].to_dict()\n",
    "chatgpt_ed[\"rating\"] = chatgpt_ed[\"chiefcomplaint\"].map(rating_dict)\n",
    "chatgpt_ed[\"rating\"].fillna(-9999, inplace=True)\n",
    "\n",
    "# Repeat the process for llama31_ed and llama31_frame\n",
    "rating_dict = llama31_frame.set_index(\"chiefcomplaint\")[\"rating\"].to_dict()\n",
    "llama31_ed[\"rating\"] = llama31_ed[\"chiefcomplaint\"].map(rating_dict)\n",
    "llama31_ed[\"rating\"].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [\n",
    "    \"temperature\",\n",
    "    \"heartrate\",\n",
    "    \"o2sat\",\n",
    "    \"sbp\",\n",
    "    \"dbp\",\n",
    "    \"resprate\",\n",
    "    \"pain\",\n",
    "    \"acuity\",\n",
    "    \"age_on_adm\",\n",
    "    \"gender\",\n",
    "    \"arrival_transport\",\n",
    "    \"rating\",\n",
    "]\n",
    "feature_column = \"los\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_train = mistral_ed[train_columns + [feature_column]]\n",
    "chatgpt_train = chatgpt_ed[train_columns + [feature_column]]\n",
    "llama31_train = llama31_ed[train_columns + [feature_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_590923/1334364932.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mistral_train[category_cols] = mistral_train[category_cols].apply(lambda col: col.astype(str))\n",
      "/tmp/ipykernel_590923/1334364932.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mistral_train[category_cols] = mistral_train[category_cols].fillna('missing')\n",
      "/tmp/ipykernel_590923/1334364932.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chatgpt_train[category_cols] = chatgpt_train[category_cols].apply(lambda col: col.astype(str))\n",
      "/tmp/ipykernel_590923/1334364932.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chatgpt_train[category_cols] = chatgpt_train[category_cols].fillna('missing')\n",
      "/tmp/ipykernel_590923/1334364932.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llama31_train[category_cols] = llama31_train[category_cols].apply(lambda col: col.astype(str))\n",
      "/tmp/ipykernel_590923/1334364932.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  llama31_train[category_cols] = llama31_train[category_cols].fillna('missing')\n"
     ]
    }
   ],
   "source": [
    "category_cols = [\"pain\", \"acuity\", \"gender\", \"arrival_transport\"]\n",
    "\n",
    "# cast category columns to string\n",
    "mistral_train[category_cols] = mistral_train[category_cols].apply(\n",
    "    lambda col: col.astype(str)\n",
    ")\n",
    "\n",
    "# replace nan in category columns with 'missing'\n",
    "mistral_train[category_cols] = mistral_train[category_cols].fillna(\"missing\")\n",
    "\n",
    "chatgpt_train[category_cols] = chatgpt_train[category_cols].apply(\n",
    "    lambda col: col.astype(str)\n",
    ")\n",
    "\n",
    "chatgpt_train[category_cols] = chatgpt_train[category_cols].fillna(\"missing\")\n",
    "\n",
    "llama31_train[category_cols] = llama31_train[category_cols].apply(\n",
    "    lambda col: col.astype(str)\n",
    ")\n",
    "\n",
    "llama31_train[category_cols] = llama31_train[category_cols].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mistral = mistral_train.drop(columns=[feature_column])\n",
    "y_mistral = mistral_train[feature_column]\n",
    "\n",
    "X_chatgpt = chatgpt_train.drop(columns=[feature_column])\n",
    "y_chatgpt = chatgpt_train[feature_column]\n",
    "\n",
    "X_llama31 = llama31_train.drop(columns=[feature_column])\n",
    "y_llama31 = llama31_train[feature_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mistral_train, X_mistral_test, y_mistral_train, y_mistral_test = train_test_split(\n",
    "    X_mistral, y_mistral, test_size=0.2, random_state=42\n",
    ")\n",
    "X_chatgpt_train, X_chatgpt_test, y_chatgpt_train, y_chatgpt_test = train_test_split(\n",
    "    X_chatgpt, y_chatgpt, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_mistral_test, X_mistral_val, y_mistral_test, y_mistral_val = train_test_split(\n",
    "    X_mistral_test, y_mistral_test, test_size=0.5, random_state=42\n",
    ")\n",
    "X_chatgpt_test, X_chatgpt_val, y_chatgpt_test, y_chatgpt_val = train_test_split(\n",
    "    X_chatgpt_test, y_chatgpt_test, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "X_llama31_train, X_llama31_test, y_llama31_train, y_llama31_test = train_test_split(\n",
    "    X_llama31, y_llama31, test_size=0.2, random_state=42\n",
    ")\n",
    "X_llama31_test, X_llama31_val, y_llama31_test, y_llama31_val = train_test_split(\n",
    "    X_llama31_test, y_llama31_test, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mistral_test.to_csv(\"../predicted_data/Xtest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_model = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    loss_function=\"RMSE\",\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    "    cat_features=category_cols,\n",
    "    task_type=\"GPU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.060467\n",
      "0:\tlearn: 397.5620832\ttest: 396.7911717\tbest: 396.7911717 (0)\ttotal: 37.4ms\tremaining: 6m 14s\n",
      "100:\tlearn: 380.1994026\ttest: 379.8039979\tbest: 379.8039979 (100)\ttotal: 2.78s\tremaining: 4m 32s\n",
      "200:\tlearn: 378.8004338\ttest: 379.1411053\tbest: 379.1411053 (200)\ttotal: 5.86s\tremaining: 4m 45s\n",
      "300:\tlearn: 377.9922687\ttest: 378.9124505\tbest: 378.9100983 (299)\ttotal: 8.94s\tremaining: 4m 48s\n",
      "400:\tlearn: 376.9313898\ttest: 378.7664245\tbest: 378.7654705 (399)\ttotal: 11.9s\tremaining: 4m 44s\n",
      "500:\tlearn: 376.1775028\ttest: 378.6829103\tbest: 378.6829103 (500)\ttotal: 14.9s\tremaining: 4m 42s\n",
      "600:\tlearn: 375.6301818\ttest: 378.6057403\tbest: 378.6057403 (600)\ttotal: 17.9s\tremaining: 4m 39s\n",
      "700:\tlearn: 375.0415185\ttest: 378.5968963\tbest: 378.5769328 (669)\ttotal: 20.8s\tremaining: 4m 35s\n",
      "bestTest = 378.5769328\n",
      "bestIteration = 669\n",
      "Shrink model to first 670 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f59e2aef730>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_model.fit(\n",
    "    X_mistral_train,\n",
    "    y_mistral_train,\n",
    "    eval_set=(X_mistral_val, y_mistral_val),\n",
    "    use_best_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mistral_model.predict(X_mistral_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save mistral predictions with real data\n",
    "mistral_test = X_mistral_test.copy()\n",
    "mistral_test[\"los\"] = y_mistral_test\n",
    "mistral_test[\"pred\"] = y_pred\n",
    "mistral_test.to_csv(\"../predicted_data/mistralpreds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral RMSE: 365.6396459282988\n",
      "Mistral MAE: 222.9922767085095\n",
      "Mistral R2: 0.0932398374277239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixs/.cache/pypoetry/virtualenvs/ed-los-nlp-llm-thesis-UneA4U57-py3.10/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = metrics.mean_squared_error(y_mistral_test, y_pred, squared=False)\n",
    "print(f\"Mistral RMSE: {rmse}\")\n",
    "mae = metrics.mean_absolute_error(y_mistral_test, y_pred)\n",
    "print(f\"Mistral MAE: {mae}\")\n",
    "r2 = metrics.r2_score(y_mistral_test, y_pred)\n",
    "print(f\"Mistral R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_model = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    loss_function=\"RMSE\",\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    "    cat_features=category_cols,\n",
    "    task_type=\"GPU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.060467\n",
      "0:\tlearn: 397.6286687\ttest: 396.8653822\tbest: 396.8653822 (0)\ttotal: 38.9ms\tremaining: 6m 28s\n",
      "100:\tlearn: 381.0577464\ttest: 380.6066160\tbest: 380.6066160 (100)\ttotal: 2.77s\tremaining: 4m 31s\n",
      "200:\tlearn: 379.6839566\ttest: 379.9821166\tbest: 379.9781068 (194)\ttotal: 5.63s\tremaining: 4m 34s\n",
      "300:\tlearn: 378.7755521\ttest: 379.7424232\tbest: 379.7398065 (299)\ttotal: 8.54s\tremaining: 4m 35s\n",
      "400:\tlearn: 377.5884067\ttest: 379.6857555\tbest: 379.6696244 (376)\ttotal: 11.5s\tremaining: 4m 34s\n",
      "500:\tlearn: 376.9496833\ttest: 379.6168326\tbest: 379.6156745 (496)\ttotal: 14.2s\tremaining: 4m 29s\n",
      "600:\tlearn: 376.3484424\ttest: 379.6042363\tbest: 379.5934959 (545)\ttotal: 17s\tremaining: 4m 26s\n",
      "bestTest = 379.5934959\n",
      "bestIteration = 545\n",
      "Shrink model to first 546 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f5961a29330>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_model.fit(\n",
    "    X_chatgpt_train,\n",
    "    y_chatgpt_train,\n",
    "    eval_set=(X_chatgpt_val, y_chatgpt_val),\n",
    "    use_best_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = chatgpt_model.predict(X_chatgpt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predcitions with original data\n",
    "chatgpt_test = X_chatgpt_test.copy()\n",
    "chatgpt_test[\"los\"] = y_chatgpt_test\n",
    "chatgpt_test[\"pred\"] = y_pred\n",
    "chatgpt_test.to_csv(\"../predicted_data/chatgpt35.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT RMSE: 366.1559438627346\n",
      "ChatGPT MAE: 223.45400060729978\n",
      "ChatGPT R2: 0.09067726559801648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixs/.cache/pypoetry/virtualenvs/ed-los-nlp-llm-thesis-UneA4U57-py3.10/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = metrics.mean_squared_error(y_chatgpt_test, y_pred, squared=False)\n",
    "print(f\"ChatGPT RMSE: {rmse}\")\n",
    "mae = metrics.mean_absolute_error(y_chatgpt_test, y_pred)\n",
    "print(f\"ChatGPT MAE: {mae}\")\n",
    "r2 = metrics.r2_score(y_chatgpt_test, y_pred)\n",
    "print(f\"ChatGPT R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama31_model = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    loss_function=\"RMSE\",\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=100,\n",
    "    cat_features=category_cols,\n",
    "    task_type=\"GPU\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.060467\n",
      "0:\tlearn: 397.5396786\ttest: 396.8237866\tbest: 396.8237866 (0)\ttotal: 33.1ms\tremaining: 5m 30s\n",
      "100:\tlearn: 379.4918110\ttest: 379.4634757\tbest: 379.4634757 (100)\ttotal: 2.64s\tremaining: 4m 19s\n",
      "200:\tlearn: 377.8878496\ttest: 378.6984156\tbest: 378.6984156 (200)\ttotal: 5.27s\tremaining: 4m 16s\n",
      "300:\tlearn: 376.9558501\ttest: 378.4189690\tbest: 378.4189690 (300)\ttotal: 8.05s\tremaining: 4m 19s\n",
      "400:\tlearn: 375.7746553\ttest: 378.3011057\tbest: 378.3011057 (400)\ttotal: 10.9s\tremaining: 4m 21s\n",
      "500:\tlearn: 374.9194601\ttest: 378.2632797\tbest: 378.2617673 (499)\ttotal: 13.6s\tremaining: 4m 17s\n",
      "600:\tlearn: 374.2294199\ttest: 378.2823046\tbest: 378.2483457 (518)\ttotal: 16.5s\tremaining: 4m 17s\n",
      "bestTest = 378.2483457\n",
      "bestIteration = 518\n",
      "Shrink model to first 519 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7fcf7fa3b5e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama31_model.fit(\n",
    "    X_llama31_train,\n",
    "    y_llama31_train,\n",
    "    eval_set=(X_llama31_val, y_llama31_val),\n",
    "    use_best_model=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = llama31_model.predict(X_llama31_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama31_test = X_llama31_test.copy()\n",
    "llama31_test[\"los\"] = y_llama31_test\n",
    "llama31_test[\"pred\"] = y_pred\n",
    "llama31_test.to_csv(\"../predicted_data/llama31.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama31 RMSE: 364.3015499224548\n",
      "Llama31 MAE: 222.0678448337494\n",
      "Llama31 R2: 0.09986445818858036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felixs/.cache/pypoetry/virtualenvs/ed-los-nlp-llm-thesis-UneA4U57-py3.10/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse = metrics.mean_squared_error(y_llama31_test, y_pred, squared=False)\n",
    "print(f\"Llama31 RMSE: {rmse}\")\n",
    "mae = metrics.mean_absolute_error(y_llama31_test, y_pred)\n",
    "print(f\"Llama31 MAE: {mae}\")\n",
    "r2 = metrics.r2_score(y_llama31_test, y_pred)\n",
    "print(f\"Llama31 R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_feature_importances(mistral_model, \"Mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_feature_importances(chatgpt_model, \"ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_regression_results(y_mistral_test, y_pred, \"Mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_regression_results(y_chatgpt_test, y_pred, \"ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_residuals(y_mistral_test, y_pred, \"Mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_residuals(y_chatgpt_test, y_pred, \"ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_feature_importances(llama31_model, \"Llama31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_utils.plot_regression_results(y_llama31_test, y_pred, \"Llama31\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed-los-nlp-llm-thesis-UneA4U57-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
