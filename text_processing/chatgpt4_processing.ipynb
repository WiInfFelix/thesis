{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import httpx\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating(s: str) -> int:\n",
    "    try:\n",
    "        return int(re.findall(r'\\d+', s)[0])\n",
    "    except IndexError:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def query_gpt35(chiefcomplaint):\n",
    "\n",
    "    header = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-turbo\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an emergency department doctor.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"<s>[INST] You are an emergency department doctor. Please rate the following chief complaint on a scale of 1 to 10, where 10 is most severe. Provide only the rating in your answer. Start your answer with the rating in a numerical format. Like this: [RATING] [Explanation]. For example: 8. The chief complaint is very severe... Here is the chief complaint: {chiefcomplaint} [/INST]\",\n",
    "            },\n",
    "        ],\n",
    "        \"max_tokens\": 3,\n",
    "    }\n",
    "\n",
    "    url = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "    try:\n",
    "        response = httpx.post(url, headers=header, json=payload, timeout=30.0)\n",
    "        response.raise_for_status()\n",
    "        rating = response.json()['choices'][0]['message']['content']\n",
    "    except (httpx.HTTPError, KeyError, IndexError) as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        rating = \"None\"\n",
    "\n",
    "    return extract_rating(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4rated_frame = pd.read_csv('../processed_data/gpt4rated_frame.csv') #pd.read_csv('../processed_data/gpt4rated_frame.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 5559/60407 [10:19<1:03:03, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 15708/60407 [30:04<1:38:11,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 26162/60407 [50:03<1:00:29,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 32008/60407 [1:01:49<59:00,  8.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno -3] Temporary failure in name resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 35108/60407 [1:07:39<46:52,  8.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 35508/60407 [1:08:49<56:13,  7.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: The read operation timed out\n",
      "An error occurred: The read operation timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 42608/60407 [1:21:25<32:10,  9.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n",
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n",
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 47008/60407 [1:29:50<19:55, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno -3] Temporary failure in name resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 50708/60407 [1:35:56<15:19, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 55608/60407 [1:44:48<11:39,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n",
      "An error occurred: Server error '502 Bad Gateway' for url 'https://api.openai.com/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60407/60407 [1:53:51<00:00,  8.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "# ...\n",
    "\n",
    "# Create a ThreadPoolExecutor with max_workers=5\n",
    "with ThreadPoolExecutor(max_workers=100) as executor:\n",
    "    futures = []\n",
    "    for i, row in tqdm(gpt4rated_frame.iterrows(), total=gpt4rated_frame.shape[0]):\n",
    "        if row['rating'] == -1:\n",
    "            # Submit each query_gpt35 call as a separate task to the executor\n",
    "            future = executor.submit(query_gpt35, row['chiefcomplaint'])\n",
    "            futures.append(future)\n",
    "\n",
    "            if len(futures) == 100:\n",
    "                # Wait for the first 5 tasks to complete before proceeding\n",
    "                for completed_future in as_completed(futures):\n",
    "                    rating = completed_future.result()\n",
    "                    gpt4rated_frame.at[i, 'rating'] = rating\n",
    "                futures = []\n",
    "\n",
    "                gpt4rated_frame.to_csv('../processed_data/gpt4rated_frame.csv', index=False)\n",
    "                sleep(1)\n",
    "\n",
    "    # Wait for the remaining tasks to complete\n",
    "    for completed_future in as_completed(futures):\n",
    "        rating = completed_future.result()\n",
    "        gpt4rated_frame.at[i, 'rating'] = rating\n",
    "\n",
    "    gpt4rated_frame.to_csv('../processed_data/gpt4rated_frame.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4rated_frame.to_csv('../processed_data/gpt4rated_frame.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "-1     59803\n",
       " 7       165\n",
       " 10       91\n",
       " 6        76\n",
       " 2        72\n",
       " 9        71\n",
       " 5        66\n",
       " 3        27\n",
       " 4        25\n",
       " 1        11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4rated_frame[\"rating\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed-los-nlp-llm-thesis-UneA4U57-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
