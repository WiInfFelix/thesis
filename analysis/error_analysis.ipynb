{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgptpreds = pd.read_csv(\"../predicted_data/chatgpt35_with_cc.csv\")\n",
    "mistralpreds = pd.read_csv(\"../predicted_data/mistralpreds_with_cc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop mistral preds with -9999 from rating column\n",
    "mistralpreds = mistralpreds.drop(mistralpreds[mistralpreds[\"rating\"] == -9999].index)\n",
    "chatgptpreds = chatgptpreds.drop(chatgptpreds[chatgptpreds[\"rating\"] == -9999].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 100 predictions from each model\n",
    "chatgpt_worst100 = chatgptpreds.sort_values(by=\"error\", ascending=False).head(200)\n",
    "mistral_worst100 = mistralpreds.sort_values(by=\"error\", ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = pd.read_csv(\"../predicted_data/Xtest.csv\")\n",
    "XTest = XTest[XTest[\"rating\"] != -9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"temperature\",\n",
    "    \"heartrate\",\n",
    "    \"o2sat\",\n",
    "    \"sbp\",\n",
    "    \"dbp\",\n",
    "    \"resprate\",\n",
    "    \"acuity\",\n",
    "    \"age_on_adm\",\n",
    "    \"rating\",\n",
    "]\n",
    "cat_cols = [\"arrival_transport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas describe to compare the distributions of the top 100 worst predictions with XTest, save to all in one df\n",
    "chatgpt_worst100_stats = chatgpt_worst100.describe()\n",
    "mistral_worst100_stats = mistral_worst100.describe()\n",
    "XTest_stats = XTest.describe()\n",
    "\n",
    "# append chatgpt, mistral, and XTest stats column names for easy ordering\n",
    "chatgpt_worst100_stats.columns = [\n",
    "    col + \"_chatgpt\" for col in chatgpt_worst100_stats.columns\n",
    "]\n",
    "mistral_worst100_stats.columns = [\n",
    "    col + \"_mistral\" for col in mistral_worst100_stats.columns\n",
    "]\n",
    "XTest_stats.columns = [col + \"_XTest\" for col in XTest_stats.columns]\n",
    "\n",
    "\n",
    "# calculate the t and p value for each column in the top 100 worst predictions\n",
    "for col in num_cols:\n",
    "    chatgpt_worst100_stats[col + \"_chatgpt_p\"] = chatgpt_worst100_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] > x).sum() / len(XTest[col]))\n",
    "    mistral_worst100_stats[col + \"_mistral_p\"] = mistral_worst100_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] > x).sum() / len(XTest[col]))\n",
    "    chatgpt_worst100_stats[col + \"_chatgpt_t\"] = chatgpt_worst100_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean())\n",
    "    mistral_worst100_stats[col + \"_mistral_t\"] = mistral_worst100_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean())\n",
    "\n",
    "    # calcute percentage of deviation from XTest\n",
    "    chatgpt_worst100_stats[col + \"_chatgpt_percent\"] = chatgpt_worst100_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean() / XTest[col].mean())\n",
    "    mistral_worst100_stats[col + \"_mistral_percent\"] = mistral_worst100_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean() / XTest[col].mean())\n",
    "\n",
    "all_stats = pd.concat(\n",
    "    [chatgpt_worst100_stats, mistral_worst100_stats, XTest_stats], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order columns by prefix before _\n",
    "all_stats = all_stats.reindex(sorted(all_stats.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats.to_csv(\"../predicted_data/top200_worst_predictions_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_top200 = chatgptpreds.sort_values(by=\"error\", ascending=True).head(200)\n",
    "mistral_top200 = mistralpreds.sort_values(by=\"error\", ascending=True).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_top200_stats = chatgpt_top200.describe()\n",
    "mistral_top200_stats = mistral_top200.describe()\n",
    "\n",
    "chatgpt_top200_stats.columns = [\n",
    "    col + \"_chatgpt\" for col in chatgpt_top200_stats.columns\n",
    "]\n",
    "mistral_top200_stats.columns = [\n",
    "    col + \"_mistral\" for col in mistral_top200_stats.columns\n",
    "]\n",
    "\n",
    "for col in num_cols:\n",
    "    chatgpt_top200_stats[col + \"_chatgpt_p\"] = chatgpt_top200_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] > x).sum() / len(XTest[col]))\n",
    "    mistral_top200_stats[col + \"_mistral_p\"] = mistral_top200_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] > x).sum() / len(XTest[col]))\n",
    "    mistral_top200_stats[col + \"_chatgpt_t\"] = chatgpt_top200_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean())\n",
    "    mistral_top200_stats[col + \"_mistral_t\"] = mistral_top200_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean())\n",
    "\n",
    "    # calcute percentage of deviation from XTest\n",
    "    chatgpt_top200_stats[col + \"_chatgpt_percent\"] = chatgpt_top200_stats[\n",
    "        col + \"_chatgpt\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean() / XTest[col].mean())\n",
    "    mistral_top200_stats[col + \"_mistral_percent\"] = mistral_top200_stats[\n",
    "        col + \"_mistral\"\n",
    "    ].apply(lambda x: (XTest[col] - x).mean() / XTest[col].mean())\n",
    "\n",
    "all_stats_top200 = pd.concat(\n",
    "    [chatgpt_top200_stats, mistral_top200_stats, XTest_stats], axis=1\n",
    ")\n",
    "\n",
    "# order by column names for easy comparison\n",
    "all_stats_top200 = all_stats_top200.reindex(sorted(all_stats_top200.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats_top200.to_csv(\"../predicted_data/top200_best_predictions_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers in num_cols for better visualization\n",
    "k = 2\n",
    "outlier_col = num_cols.copy()\n",
    "outlier_col.remove(\"rating\")\n",
    "outlier_col.remove(\"acuity\")\n",
    "outlier_col.remove(\"age_on_adm\")\n",
    "\n",
    "\n",
    "for col in outlier_col:\n",
    "    Q1 = XTest[col].quantile(0.25)\n",
    "    Q3 = XTest[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    XTest = XTest[(XTest[col] >= (Q1 - k * IQR)) & (XTest[col] <= (Q3 + k * IQR))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compare_distributions_violinplot(\n",
    "    data1,\n",
    "    data2,\n",
    "    columns,\n",
    "    data1_label=\"Data 1\",\n",
    "    data2_label=\"Data 2\",\n",
    "    title=\"Distributions of numerical features\",\n",
    "    model_name=\"Model\",\n",
    "    order_type=\"Best\",\n",
    "):\n",
    "    # Set the style of seaborn\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Iterate over the columns and create violinplots for each feature\n",
    "    for col in columns:\n",
    "        # Create a new figure for each column\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # apply log scale if max value is greater than 30\n",
    "        needs_log = max(data1[col].max(), data2[col].max()) > 30\n",
    "\n",
    "        # Create a new DataFrame for seaborn to handle\n",
    "        combined_data = pd.DataFrame(\n",
    "            {data1_label: data1[col], data2_label: data2[col]}\n",
    "        ).melt(var_name=\"Dataset\", value_name=col)\n",
    "\n",
    "        # Create a violin plot\n",
    "        ax = sns.violinplot(x=\"Dataset\", y=col, data=combined_data)\n",
    "\n",
    "        # Apply log scale if necessary\n",
    "        if needs_log:\n",
    "            ax.set_yscale(\"log\")\n",
    "\n",
    "        # Set plot title\n",
    "        plt.title(f\"{title}: {col}\")\n",
    "\n",
    "        # Save the plot\n",
    "        plt.savefig(f\"./{model_name}_{order_type}_{col}_violinplot.png\")\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions_hist(\n",
    "    data1,\n",
    "    data2,\n",
    "    columns,\n",
    "    data1_label=\"Data 1\",\n",
    "    data2_label=\"Data 2\",\n",
    "    title=\"Distributions of numerical features\",\n",
    "    figsize=(10, 30),\n",
    "):\n",
    "    # Set the style of seaborn\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # Create a figure and a set of subplots\n",
    "    fig, axes = plt.subplots(nrows=len(columns), ncols=1, figsize=figsize)\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    fig.tight_layout(pad=5.0)\n",
    "\n",
    "    # Set the title of the figure\n",
    "    fig.suptitle(title, y=1.02)\n",
    "\n",
    "    # Iterate over the columns and create histograms for each feature\n",
    "    for i, col in enumerate(columns):\n",
    "        # apply log scale if max value is greater than 30\n",
    "        needs_log = max(data1[col].max(), data2[col].max()) > 30\n",
    "\n",
    "        # Create a histogram for the feature\n",
    "        sns.histplot(data1[col], ax=axes[i], label=data1_label, color=\"blue\", kde=True)\n",
    "        sns.histplot(data2[col], ax=axes[i], label=data2_label, color=\"red\", kde=True)\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid of plots that compares the distribution of numerical features for the worst 100 predictions for mistral and test data\n",
    "compare_distributions_violinplot(\n",
    "    mistral_worst100,\n",
    "    XTest,\n",
    "    num_cols,\n",
    "    data1_label=\"Mistral\",\n",
    "    data2_label=\"Test Data\",\n",
    "    title=\"Distributions of numerical features for Mistral worst 100 predictions and test data\",\n",
    "    model_name=\"Mistral\",\n",
    "    order_type=\"worst\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a grid of plots that compares the distribution of numerical features for the worst 100 predictions for chatgpt and test data\n",
    "compare_distributions_violinplot(\n",
    "    chatgpt_worst100,\n",
    "    XTest,\n",
    "    num_cols,\n",
    "    data1_label=\"ChatGPT\",\n",
    "    data2_label=\"Test Data\",\n",
    "    title=\"Distributions of numerical features for ChatGPT worst 100 predictions and test data\",\n",
    "    model_name=\"ChatGPT\",\n",
    "    order_type=\"worst\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_best = chatgptpreds.sort_values(by=\"error\", ascending=True).head(200)\n",
    "mistral_best = mistralpreds.sort_values(by=\"error\", ascending=True).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_distributions_violinplot(\n",
    "    mistral_best,\n",
    "    XTest,\n",
    "    num_cols,\n",
    "    data1_label=\"Mistral\",\n",
    "    data2_label=\"Test Data\",\n",
    "    title=\"Distributions of numerical features for Mistral best 100 predictions and test data\",\n",
    "    model_name=\"Mistral\",\n",
    "    order_type=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_distributions_violinplot(\n",
    "    chatgpt_best,\n",
    "    XTest,\n",
    "    num_cols,\n",
    "    data1_label=\"Mistral\",\n",
    "    data2_label=\"Test Data\",\n",
    "    title=\"Distributions of numerical features for Mistral best 100 predictions and test data\",\n",
    "    model_name=\"ChatGPT\",\n",
    "    order_type=\"best\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the arrival_transport distributions with chi squared test\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# get the counts of each category in the arrival_transport column for the worst 100 predictions\n",
    "mistral_worst100_counts = mistral_worst100[\"arrival_transport\"].value_counts()\n",
    "chatgpt_worst100_counts = chatgpt_worst100[\"arrival_transport\"].value_counts()\n",
    "\n",
    "# get the counts of each category in the arrival_transport column for the test data\n",
    "XTest_counts = XTest[\"arrival_transport\"].value_counts()\n",
    "\n",
    "# create a contingency table\n",
    "contingency_table_mistral = pd.concat(\n",
    "    [mistral_worst100_counts, XTest_counts], axis=1, keys=[\"mistral\", \"XTest\"]\n",
    ").fillna(0)\n",
    "contingency_table_chatgpt = pd.concat(\n",
    "    [chatgpt_worst100_counts, XTest_counts], axis=1, keys=[\"chatgpt\", \"XTest\"]\n",
    ").fillna(0)\n",
    "\n",
    "# perform the chi squared test\n",
    "chi2_mistral, p_mistral, _, _ = chi2_contingency(contingency_table_mistral)\n",
    "chi2_chatgpt, p_chatgpt, _, _ = chi2_contingency(contingency_table_chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Chi-squared test for Mistral worst 100 predictions: chi2={chi2_mistral}, p={p_mistral}\"\n",
    ")\n",
    "print(\n",
    "    f\"Chi-squared test for ChatGPT worst 100 predictions: chi2={chi2_chatgpt}, p={p_chatgpt}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the value counts in percent for mistral, chatgpt and XTest\n",
    "print(\"Mistral worst 100 predictions:\")\n",
    "print(mistral_worst100_counts / len(mistral_worst100))\n",
    "\n",
    "print(\"ChatGPT worst 100 predictions:\")\n",
    "print(chatgpt_worst100_counts / len(chatgpt_worst100))\n",
    "\n",
    "print(\"X_Test\")\n",
    "print(XTest_counts / len(XTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_top200_counts = mistral_top200[\"arrival_transport\"].value_counts()\n",
    "chatgpt_top200_counts = chatgpt_top200[\"arrival_transport\"].value_counts()\n",
    "\n",
    "contingency_table_mistral_top200 = pd.concat(\n",
    "    [mistral_top200_counts, XTest_counts], axis=1, keys=[\"mistral\", \"XTest\"]\n",
    ").fillna(0)\n",
    "contingency_table_chatgpt_top200 = pd.concat(\n",
    "    [chatgpt_top200_counts, XTest_counts], axis=1, keys=[\"chatgpt\", \"XTest\"]\n",
    ").fillna(0)\n",
    "\n",
    "chi2_mistral_top200, p_mistral_top200, _, _ = chi2_contingency(\n",
    "    contingency_table_mistral_top200\n",
    ")\n",
    "chi2_chatgpt_top200, p_chatgpt_top200, _, _ = chi2_contingency(\n",
    "    contingency_table_chatgpt_top200\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Chi-squared test for Mistral top 200 predictions: chi2={chi2_mistral_top200}, p={p_mistral_top200}\"\n",
    ")\n",
    "print(\n",
    "    f\"Chi-squared test for ChatGPT top 200 predictions: chi2={chi2_chatgpt_top200}, p={p_chatgpt_top200}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mistral top 200 predictions:\")\n",
    "print(mistral_top200_counts / len(mistral_top200))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"ChatGPT top 200 predictions:\")\n",
    "print(chatgpt_top200_counts / len(chatgpt_top200))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"X_Test\")\n",
    "print(XTest_counts / len(XTest))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the average lenght of chiefcomplaint and compare\n",
    "chatgpt_top200[\"chiefcomplaint_len\"] = chatgpt_top200[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "mistral_top200[\"chiefcomplaint_len\"] = mistral_top200[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"ChatGPT top 200 average chiefcomplaint length: {chatgpt_top200['chiefcomplaint_len'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mistral top 200 average chiefcomplaint length: {mistral_top200['chiefcomplaint_len'].mean()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average word count of and compare\n",
    "chatgpt_top200[\"chiefcomplaint_word_count\"] = chatgpt_top200[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x.split())\n",
    ")\n",
    "mistral_top200[\"chiefcomplaint_word_count\"] = mistral_top200[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x.split())\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"ChatGPT top 200 average chiefcomplaint word count: {chatgpt_top200['chiefcomplaint_word_count'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mistral top 200 average chiefcomplaint word count: {mistral_top200['chiefcomplaint_word_count'].mean()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but for worst\n",
    "chatgpt_worst100[\"chiefcomplaint_len\"] = chatgpt_worst100[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "mistral_worst100[\"chiefcomplaint_len\"] = mistral_worst100[\"chiefcomplaint\"].apply(\n",
    "    lambda x: len(x)\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"ChatGPT worst 100 average chiefcomplaint length: {chatgpt_worst100['chiefcomplaint_len'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mistral worst 100 average chiefcomplaint length: {mistral_worst100['chiefcomplaint_len'].mean()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_worst100[\"chiefcomplaint_word_count\"] = chatgpt_worst100[\n",
    "    \"chiefcomplaint\"\n",
    "].apply(lambda x: len(x.split()))\n",
    "mistral_worst100[\"chiefcomplaint_word_count\"] = mistral_worst100[\n",
    "    \"chiefcomplaint\"\n",
    "].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\n",
    "    f\"ChatGPT worst 100 average chiefcomplaint word count: {chatgpt_worst100['chiefcomplaint_word_count'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Mistral worst 100 average chiefcomplaint word count: {mistral_worst100['chiefcomplaint_word_count'].mean()}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed-los-nlp-llm-thesis-UneA4U57-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
